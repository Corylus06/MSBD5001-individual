{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficFile = 'train.csv'\n",
    "traffic = pd.read_csv(trafficFile, index_col=\"id\", parse_dates=[1], dayfirst=True)\n",
    "traffic['hour'] = pd.to_datetime(traffic['date']).apply(lambda x: x.hour)\n",
    "traffic['hour'] = traffic['hour']/23\n",
    "traffic['weekday'] = pd.to_datetime(traffic['date']).apply(lambda x: x.dayofweek)\n",
    "traffic['weekday'] = traffic['weekday']/6\n",
    "traffic['month']=pd.to_datetime(traffic['date']).apply(lambda x:x.month)\n",
    "traffic['month']=traffic['month']/12\n",
    "traffic['day']=pd.to_datetime(traffic['date']).apply(lambda x:x.day)\n",
    "traffic['day']=traffic['day']/30\n",
    "max_time = max(traffic['date'])\n",
    "min_time = min(traffic['date'])\n",
    "traffic['time'] = (traffic['date']-min_time)/(max_time-min_time)\n",
    "X = traffic[['time','weekday','hour','month','day']]\n",
    "y = traffic['speed']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.04,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"test.csv\", index_col='id', parse_dates=[1], dayfirst=True)\n",
    "# data_test['datetime'] = pd.to_datetime(data_test['date'])\n",
    "data_test['hour'] = pd.to_datetime(data_test['date']).apply(lambda x: x.hour)\n",
    "data_test['hour'] = data_test['hour']/23\n",
    "data_test['weekday'] = pd.to_datetime(data_test['date']).apply(lambda x: x.dayofweek)\n",
    "data_test['weekday'] = data_test['weekday']/6\n",
    "data_test['month'] = pd.to_datetime(data_test['date']).apply(lambda x:x.month)\n",
    "data_test['month'] = data_test['month']/12\n",
    "data_test['day'] = pd.to_datetime(data_test['date']).apply(lambda x:x.day)\n",
    "data_test['day'] = data_test['day']/30\n",
    "data_test['time'] = (data_test['date']-min_time)/(max_time-min_time)\n",
    "predict_x = data_test[['time','weekday','hour','month','day']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Training and Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attain three xgboost model that have achieved a relatively good result, to improve the generaliztion ability, we choose to ensemble those models. Here two layers of model fusion are used. Level 1 uses: 3 XGBoost models with different parameters, and Level 2 uses LinearRegression to fit the results of the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Model 0 fold 0\n",
      "Fit Model 0 fold 1\n",
      "Fit Model 0 fold 2\n",
      "Fit Model 0 fold 3\n",
      "Fit Model 0 fold 4\n",
      "Fit Model 0 fold 5\n",
      "Fit Model 0 fold 6\n",
      "Fit Model 0 fold 7\n",
      "Fit Model 0 fold 8\n",
      "Fit Model 0 fold 9\n",
      "Fit Model 0 fold 10\n",
      "Fit Model 0 fold 11\n",
      "Fit Model 0 fold 12\n",
      "Fit Model 0 fold 13\n",
      "Fit Model 0 fold 14\n",
      "Fit Model 0 fold 15\n",
      "Fit Model 0 fold 16\n",
      "Fit Model 0 fold 17\n",
      "Fit Model 0 fold 18\n",
      "Fit Model 0 fold 19\n",
      "Fit Model 1 fold 0\n",
      "Fit Model 1 fold 1\n",
      "Fit Model 1 fold 2\n",
      "Fit Model 1 fold 3\n",
      "Fit Model 1 fold 4\n",
      "Fit Model 1 fold 5\n",
      "Fit Model 1 fold 6\n",
      "Fit Model 1 fold 7\n",
      "Fit Model 1 fold 8\n",
      "Fit Model 1 fold 9\n",
      "Fit Model 1 fold 10\n",
      "Fit Model 1 fold 11\n",
      "Fit Model 1 fold 12\n",
      "Fit Model 1 fold 13\n",
      "Fit Model 1 fold 14\n",
      "Fit Model 1 fold 15\n",
      "Fit Model 1 fold 16\n",
      "Fit Model 1 fold 17\n",
      "Fit Model 1 fold 18\n",
      "Fit Model 1 fold 19\n",
      "Fit Model 2 fold 0\n",
      "Fit Model 2 fold 1\n",
      "Fit Model 2 fold 2\n",
      "Fit Model 2 fold 3\n",
      "Fit Model 2 fold 4\n",
      "Fit Model 2 fold 5\n",
      "Fit Model 2 fold 6\n",
      "Fit Model 2 fold 7\n",
      "Fit Model 2 fold 8\n",
      "Fit Model 2 fold 9\n",
      "Fit Model 2 fold 10\n",
      "Fit Model 2 fold 11\n",
      "Fit Model 2 fold 12\n",
      "Fit Model 2 fold 13\n",
      "Fit Model 2 fold 14\n",
      "Fit Model 2 fold 15\n",
      "Fit Model 2 fold 16\n",
      "Fit Model 2 fold 17\n",
      "Fit Model 2 fold 18\n",
      "Fit Model 2 fold 19\n"
     ]
    }
   ],
   "source": [
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(KFold(n_splits=self.n_splits, shuffle=True, random_state=50).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                y_holdout = y[test_idx]\n",
    "                print (\"Fit Model %d fold %d\" % (i, j))\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_holdout)[:]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict(T)[:]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "        # results = cross_val_score(self.stacker, S_train, y, cv=5, scoring='r2')\n",
    "        # print(\"Stacker score: %.4f (%.4f)\" % (results.mean(), results.std()))\n",
    "        # exit()\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict(S_test)[:]\n",
    "        return res\n",
    "\n",
    "# xgb params: 9.86\n",
    "# xgb_params2 = {'learning_rate': 0.1, 'n_estimators': 148, 'max_depth': 10, 'min_child_weight': 1, 'seed': 0,\n",
    "#                 'subsample': 0.82, 'colsample_bytree': 1.0, 'gamma': 0.1, 'reg_alpha': 0.39, 'reg_lambda': 4.6,\n",
    "#                 'n_jobs':-1}\n",
    "xgb_params1 = {'learning_rate': 0.1, 'n_estimators': 500, 'max_depth': 10, 'min_child_weight': 1, 'seed': 0,\n",
    "                'subsample': 0.82, 'colsample_bytree': 1.0, 'gamma': 0.1, 'reg_alpha': 0.39, 'reg_lambda': 4.6,\n",
    "                'n_jobs':-1}\n",
    "# xgb params: 9.66\n",
    "xgb_params2 = {'learning_rate': 0.1, 'n_estimators': 500, 'max_depth': 9, 'min_child_weight': 1, 'seed': 0,\n",
    "                'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 3.7, 'reg_lambda': 0.36,\n",
    "                'n_jobs':-1}\n",
    "xgb_params3 = {'learning_rate':0.1,'n_estimators':184,'max_depth':10,'min_child_weight':1,'subsample':0.8,'colsample_bytree':1.0,\n",
    "                           'gamma':0,'reg_alpha':0,'reg_lambda':1,'n_jobs':-1}\n",
    "\n",
    "\n",
    "# XGB model\n",
    "xgb_model1 = XGBRegressor(**xgb_params1)\n",
    "xgb_model2 = XGBRegressor(**xgb_params2)\n",
    "xgb_model3 = XGBRegressor(**xgb_params3)\n",
    "\n",
    "stack = Ensemble(n_splits=20,\n",
    "        stacker=LinearRegression(),\n",
    "        base_models=(xgb_model1, xgb_model2,xgb_model3))\n",
    "y_predict = stack.fit_predict(X, y, predict_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.447185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.135054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.927021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.940552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.856981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>13.835074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>22.457817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>45.070239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>40.464029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>41.264620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3504 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          speed\n",
       "0     48.447185\n",
       "1     48.135054\n",
       "2     35.927021\n",
       "3     30.940552\n",
       "4     38.856981\n",
       "...         ...\n",
       "3499  13.835074\n",
       "3500  22.457817\n",
       "3501  45.070239\n",
       "3502  40.464029\n",
       "3503  41.264620\n",
       "\n",
       "[3504 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out = pd.DataFrame(y_predict,columns=['speed'])\n",
    "y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out.to_csv(\"xgboost_final_output.csv\",index=True,index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
